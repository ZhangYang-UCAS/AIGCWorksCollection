# Awesome-Image2video

## Code has been released

1. I2VGen-XL: High-Quality Image-to-Video Synthesis via Cascaded Diffusion Models (2023)
   code: https://github.com/ali-vilab/VGen
2. AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning (2023)
   code: https://github.com/guoyww/AnimateDiff
3. DreamTalk: When Expressive Talking Head Generation Meets Diffusion Probabilistic Models (2023)
   code: https://github.com/ali-vilab/dreamtalk 
4. AnimateLCM: Accelerating the Animation of Personalized Diffusion Models and Adapters with Decoupled Consistency Learning (2024)
   code: https://github.com/G-U-N/AnimateLCM
5. Stable Video Diffusion (2024)
   codeï¼šhttps://stability.ai/news/stable-video-diffusion-open-ai-video-model
6. DragAnything: Motion Control for Anything using Entity Representation (2024)
   code: https://github.com/showlab/DragAnything

## Code has not been released 
1. LivePhoto: Real Image Animation with Text-guided Motion Control (2023)
2. I2V-Adapter: A General Image-to-Video Adapter for Video Diffusion Models (2023)
3. DreamVideo: High-Fidelity Image-to-Video Generation with Image Retention and Text Guidance (2023)
4. MotionCrafter: One-Shot Motion Customization of Diffusion Models (2023)
5. SparseCtrl: Adding Sparse Controls to Text-to-Video Diffusion Models (2023)
6. MicroCinema: A Divide-and-Conquer Approach for Text-to-Video Generation (2023)
7. Moonshot: Towards Controllable Video Generation and Editing with Multimodal Conditions (2024)
8. Motion-I2V: Consistent and Controllable Image-to-Video Generation with Explicit Motion Modeling (2024)
9. Follow-Your-Click: Open-domain Regional Image Animation via Short Prompts(2024)

## Workflow

1. https://www.reddit.com/r/StableDiffusion/comments/1bpl6gx/animatediff_is_reaching_a_whole_new_level_of/
