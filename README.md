# Awesome-Image2video

## Code Releases

1. **I2VGen-XL:** High-Quality Image-to-Video Synthesis via Cascaded Diffusion Models (2023)
   - [[Project](https://i2vgen-xl.github.io/)]
     [[paper](https://arxiv.org/abs/2311.04145)]
     [[GitHub](https://github.com/ali-vilab/VGen)]

2. **AnimateDiff:** Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning (2023)
   - [[Project](https://animatediff.github.io/)]
     [[paper](https://arxiv.org/abs/2307.04725)]
     [[GitHub](https://github.com/guoyww/AnimateDiff)]

4. **DreamTalk:** When Expressive Talking Head Generation Meets Diffusion Probabilistic Models (2023)
   - [[Project](https://dreamtalk-project.github.io/)]
     [[paper](https://arxiv.org/abs/2312.09767)]
     [[GitHub](https://github.com/ali-vilab/dreamtalk)]

5. **AnimateLCM:** Accelerating the Animation of Personalized Diffusion Models and Adapters with Decoupled Consistency Learning (2024)
   - [[paper](https://arxiv.org/abs/2402.00769)]
     [[GitHub](https://github.com/G-U-N/AnimateLCM)]

6. **Stable Video Diffusion** (2024)
   - [Project](https://stability.ai/news/stable-video-diffusion-open-ai-video-model)
     [[paper](https://stability.ai/research/stable-video-diffusion-scaling-latent-video-diffusion-models-to-large-datasets)]
     [[huggingface](https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt)]

8. **DragAnything:** Motion Control for Anything using Entity Representation (2024)
   - [[Project](https://weijiawu.github.io/draganything_page/)]
      [[paper](https://arxiv.org/abs/2403.07420)]
      [[GitHub](https://github.com/showlab/DragAnything)]

## Code Not Yet Released

1. **LivePhoto:** Real Image Animation with Text-guided Motion Control (2023)
   - [[Project](https://xavierchen34.github.io/LivePhoto-Page/)]
      [[paper](https://arxiv.org/abs/2312.02928)]
      [[GitHub](https://github.com/XavierCHEN34/LivePhoto)](comming soon)
3. **I2V-Adapter:** A General Image-to-Video Adapter for Video Diffusion Models (2023)
4. **DreamVideo:** High-Fidelity Image-to-Video Generation with Image Retention and Text Guidance (2023)
5. **MotionCrafter:** One-Shot Motion Customization of Diffusion Models (2023)
6. **SparseCtrl:** Adding Sparse Controls to Text-to-Video Diffusion Models (2023)
7. **MicroCinema:** A Divide-and-Conquer Approach for Text-to-Video Generation (2023)
8. **Moonshot:** Towards Controllable Video Generation and Editing with Multimodal Conditions (2024)
9. **Motion-I2V:** Consistent and Controllable Image-to-Video Generation with Explicit Motion Modeling (2024)
10. **Follow-Your-Click:** Open-domain Regional Image Animation via Short Prompts (2024)

## Workflow

1. [Reddit Post](https://www.reddit.com/r/StableDiffusion/comments/1bpl6gx/animatediff_is_reaching_a_whole_new_level_of/) - *AnimateDiff* is reaching a whole new level of...
