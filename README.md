# Awesome-Image2video

## Code Releases

1. **I2VGen-XL:** High-Quality Image-to-Video Synthesis via Cascaded Diffusion Models (2023)
   - [[Project](https://i2vgen-xl.github.io/)]
     [[paper](https://arxiv.org/abs/2311.04145)]
     [[GitHub](https://github.com/ali-vilab/VGen)]

2. **AnimateDiff:** Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning (2023)
   - [[Project](https://animatediff.github.io/)]
     [[paper](https://arxiv.org/abs/2307.04725)]
     [[GitHub](https://github.com/guoyww/AnimateDiff)]

3. **DreamTalk:** When Expressive Talking Head Generation Meets Diffusion Probabilistic Models (2023)
   - [[Project](https://dreamtalk-project.github.io/)]
     [[paper](https://arxiv.org/abs/2312.09767)]
     [[GitHub](https://github.com/ali-vilab/dreamtalk)]

4. **MotionDirector:** Motion Customization of Text-to-Video Diffusion Models
   - [[Project](https://showlab.github.io/MotionDirector/)]
     [[paper](https://arxiv.org/abs/2310.08465)]
     [[GitHub](https://github.com/showlab/MotionDirector)]
     
5. **AnimateLCM:** Accelerating the Animation of Personalized Diffusion Models and Adapters with Decoupled Consistency Learning (2024)
   - [[paper](https://arxiv.org/abs/2402.00769)]
     [[GitHub](https://github.com/G-U-N/AnimateLCM)]

6. **Stable Video Diffusion** (2024)
   - [Project](https://stability.ai/news/stable-video-diffusion-open-ai-video-model)
     [[paper](https://stability.ai/research/stable-video-diffusion-scaling-latent-video-diffusion-models-to-large-datasets)]
     [[huggingface](https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt)]

7. **DragAnything:** Motion Control for Anything using Entity Representation (2024)
   - [[Project](https://weijiawu.github.io/draganything_page/)]
      [[paper](https://arxiv.org/abs/2403.07420)]
      [[GitHub](https://github.com/showlab/DragAnything)]

8. **AniPortrait:** Audio-Driven Synthesis of Photorealistic Portrait Animation (2024)
   -  [[paper](https://arxiv.org/abs/2403.17694)]
      [[GitHub](https://github.com/Zejun-Yang/AniPortrait)]

## Code Not Yet Released

1. **LivePhoto:** Real Image Animation with Text-guided Motion Control (2023)
   - [[Project](https://xavierchen34.github.io/LivePhoto-Page/)]
      [[paper](https://arxiv.org/abs/2312.02928)]
      [[GitHub](https://github.com/XavierCHEN34/LivePhoto)](comming soon)
     
2. **I2V-Adapter:** A General Image-to-Video Adapter for Video Diffusion Models (2023)
   - [[paper](https://arxiv.org/abs/2312.16693)]
     [[GitHub]](no code)
     
3. **DreamVideo:** High-Fidelity Image-to-Video Generation with Image Retention and Text Guidance (2023)
   - [[Project](https://anonymous0769.github.io/DreamVideo/)]
      [[paper](https://arxiv.org/abs/2312.03018)]
      [[GitHub](https://github.com/anonymous0769/DreamVideo)](comming soon)
     
4. **MotionCrafter:** One-Shot Motion Customization of Diffusion Models (2023)
   - [[Project](https://zyxelsa.github.io/homepage-motioncrafter/)]
      [[paper](https://arxiv.org/abs/2312.05288)]
      [[GitHub](https://github.com/zyxElsa/MotionCrafter)](comming soon)
5. **SparseCtrl:** Adding Sparse Controls to Text-to-Video Diffusion Models (2023)
   - [[Project](https://guoyww.github.io/projects/SparseCtrl/)]
      [[paper](https://arxiv.org/abs/2311.16933)]
      [[GitHub](https://github.com/guoyww/AnimateDiff#202312-animatediff-v3-and-sparsectrl)]
     
6. **MicroCinema:** A Divide-and-Conquer Approach for Text-to-Video Generation (2023)
   - [[Project](https://wangyanhui666.github.io/MicroCinema.github.io/)]
      [[paper](https://arxiv.org/abs/2311.18829)]
      [[GitHub]](no code)
     
7. **Moonshot:** Towards Controllable Video Generation and Editing with Multimodal Conditions (2024)
   - [[Project](https://showlab.github.io/Moonshot/)]
      [[paper](https://arxiv.org/abs/2401.01827)]
      [[GitHub]](comming soon)
     
8. **Motion-I2V:** Consistent and Controllable Image-to-Video Generation with Explicit Motion Modeling (2024)
   -  [[Project](https://xiaoyushi97.github.io/Motion-I2V/)]
      [[paper](https://arxiv.org/abs/2401.15977)]
      [(no code)]
     
9. **Follow-Your-Click:** Open-domain Regional Image Animation via Short Prompts (2024)
   -  [[Project](https://follow-your-click.github.io/)]
      [[paper](https://arxiv.org/abs/2403.08268)]
      [[GitHub](https://github.com/mayuelala/FollowYourClick)](comming soon)

10. ** X-Portrait **Expressive Portrait Animation with Hierarchical Motion Attention (2024)
   -  [[paper](https://arxiv.org/abs/2403.15931)]
      [(no code)]
## Workflow

1. [Reddit Post](https://www.reddit.com/r/StableDiffusion/comments/1bpl6gx/animatediff_is_reaching_a_whole_new_level_of/) - *AnimateDiff* is reaching a whole new level
